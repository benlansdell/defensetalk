<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <title>Neural encoding in application, development and beyond</title>
      <meta name="viewport"
	  content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <!--<link rel="stylesheet" href="reveal.js/css/reveal.min.css">-->
    <link rel="stylesheet" href="reveal.js/css/reveal.min.css">
    <!--<link rel="stylesheet" href="reveal.js/css/theme/black.css" id="theme">-->
    <link rel="stylesheet" href="cust_black.css" id="theme">
    <link rel="stylesheet" href="reveal.js/lib/css/zenburn.css">
    <script>
      document.write('<link rel="stylesheet" href="reveal.js/css/print/'+(window.location.search.match(/print-pdf/gi) ? 'pdf' : 'paper')+'.css" type="text/css" media="print">');
    </script>
    <!--<script src="js/three.js"></script>-->

    <script src="js/three.min.js"></script>
    <script src="js/OrbitControls.js"></script>
    <script src="js/KeyboardState.js"></script>
    <script type="text/x-mathjax-config">
	    MathJax.Hub.Config({TeX: {extensions: ["color.js"]}});
    </script>

    <!--[if lt IE 9]>
    <script src="reveal.js/lib/js/html5shiv.js"></script>
    <![endif]-->

<!-- Printing and PDF exports -->
<script>
    var link = document.createElement( 'link' );
    link.rel = 'stylesheet';
    link.type = 'text/css';
    link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
    document.getElementsByTagName( 'head' )[0].appendChild( link );
</script>
  </head>

  <body>
    <!-- Slides! -->
    <div class="reveal">
      <div class="slides">
        <!--<section data-background="assets/dst2_background.png">-->
        <section data-background-color="#ffffff">
          <h1 style="color: #000000">Neural encoding in application, development and beyond</h1>
	  <br><hr>
	  <p style="text-align: center; font-size: larger; text-shadow: 0px 0px 0px #0000ff;">Ben Lansdell<br> Applied Mathematics<br><br>
	  	Final examination, May 9th 2017</p>
	  <aside class="notes">
	    <span style="color: red">
	    </span> •

	    • <span style="color: green"></span>
	  </aside>
        </section>

<!-- ----------------------------------------------------------------------- -->
<!-- ----------------------------------------------------------------------- -->
<!-- ----------------------------------------------------------------------- -->

	<!-- <section data-background-color="#ffffff">
	  	<ul>
	  		<li> Dimensionality reduction in neuroscience
	    <center><img src="assets/glmuncoupled.svg" width="60%"></center>
<p class="rcred">Aljadeff, <b>Lansdell</b>, Fairhall, Kleinfeld 2016. <em>Neuron</em><br>
Pang, <b>Lansdell</b>, Fairhall 2016 <em>Current Biology</em></p>
	  	</ul>

	  <aside class="notes">
	    <span style="color: red"></span> •
	    • <span style="color: green"></span>
	  </aside>
	</section> -->

	<section data-background-color="#ffffff">
	  <h2>Neural activity represents the external world and motor behavior</h2>

    <img src="assets/frog.png" width="100%">
	<p class="rcred">Yuste 2015</p>

	  <aside class="notes">
	    <span style="color: red"></span> •

From the 1950s onward, single neuron recordings have been used to study the
relation between neural activity and features in the outside world.

An early study of this nature by Barlow, and also by Lettvin and McCulloch and Pitts
is in frog vision. Here recordings of optic fibres from the frog retina allow recording
on individual neurons. The authors find cells that respond strongly to small moving spots
relative to the background. They hypothesize that these neurons act as a type of 'fly detector', 
and that therefore individual neurons activity are functionally and even perceptually significant.

From this time onward, considerable progress has been made characterizing the encoding properties
of single neurons.

However the focus and availability of single neuron recordings means there is the temptation to
ascribe function to a neuron's tuning curve when it shouldn't be. I will spend the next section talking
about the ambiguity in encodings in motor cortex.

Perhaps if we had more comprehensive access to a neural population's activity the
encoded relation between stimulus and activity would be explained away,
and their function within the entire circuit would become clear. These studies
are now possible in a number of lower-organisms -- one of which I will discuss in the
last half of my talk.

	    • <span style="color: green"></span>
	  </aside>
	</section>

	<section data-background-color="#ffffff">
	  <h2>Outline</h2>

    <img src="assets/outline.svg" width="100%">

	  <aside class="notes">
	    <span style="color: red"></span> •

	    Ideas for lead in...

	    The brain as a computer: representation is a key component
	    How does the brain represent?

	    Fly detector (Barlow)


	    • <span style="color: green"></span>
	  </aside>
	</section>
	
	<section data-background-color="#ffffff">
	  <h2>Outline</h2>

    <img src="assets/outline_1.svg" width="100%">

	  <aside class="notes">
	    <span style="color: red"></span> •

	    • <span style="color: green"></span>
	  </aside>
	</section>

<!-- ----------------------------------------------------------------------- -->
<!-- ----------------------------------------------------------------------- -->
<!-- ----------------------------------------------------------------------- -->

	<section data-background-color="#ffffff">
		<h2>Encoding models and motor cortex</h2>
		<div id="left">
	    <img src="assets/motorstim.png" width="90%">
	    <p class="lcred">Phillips and Porter 1977</p>
		</div>
		<div id="right">
		<ul>
			<li> Motor cortical neuron representations are complex: 
				<ul><li>kinetics &#8212; single-unit recordings, stimulation evoked responses (1960s)
				<li> kinematics &#8212; center-out task (1980s)
				<li> dynamics &#8212; high-dimensional recordings (2000s)</ul>
			<li class="fragment"> Understanding motor encoding can inform design of BCIs for control of prosthetic limbs
		</ul>
	</div>
	    <aside class="notes">
	    <span style="color: red"></span> •


	    • <span style="color: green"></span>
	  </aside>	</section>

	<section data-background-color="#ffffff">
		<h2>Intracortical arrays provide state-of-the-art BCI control</h2>
	  <div id="left">
	    <center><img src="assets/utah.png" width="45%">
	    <p class="rcred"></p>
	  </div>
	  <div id="right">
	  </div>
	    <center><img src="assets/motorcortex.png" width="40%">
	    <ul><li>Monkeys can be trained to volitionally control individual neurons through feedback and conditioning [Fetz 1969]
	    	<li>Neurons chosen independently of natural movement association [Moritz and Fetz 2011]
	    	<li>Conversely, other studies report brain-control mappings which utilize activity observed during the natural motor repertoire are most effective [Sadtler et al 2014]
	    </ul>
	  <aside class="notes">
	    <span style="color: red"></span> •
	    • <span style="color: green"></span>
	  </aside>
	</section>

	<section data-background-color="#ffffff">
		<h2>Dual-control BCIs</h2>
	    <img src="assets/dualcontrolBCI.png" width="40%">
	    <img src="assets/easyharddiag2.png" width="50%">
	    <p class="rcred">Milovanovic et al 2015</p>
	    <ul>
	  		<li> Allow stroke patients to regain functionality through co-opting
	  			healthy motor cortex to control neural prosthetic in conjunction with residual movement 
   		<li> Do neurons strongly associated with contralateral motion make poor control units due to the potential interference imposed by concurrent hand movement?
   		</ul> 
	  <aside class="notes">
	    <span style="color: red"></span> •
	    • <span style="color: green"></span>
	  </aside>
	</section>

	<section data-background-color="#ffffff">
		<h2>Dual-control BCIs</h2>
		<img src="assets/dc_perf.png" width="55%">
		<p class="rcred">Milovanovic et al 2015</p>
	    <ul>
	    	<li> Previous studies show performance independent of unit tuning [Milovanovic et al 2015]
	    </ul>
	  <aside class="notes">
	    <span style="color: red"></span> •
	    • <span style="color: green"></span>
	  </aside>
	</section>

	<section data-background-color="#ffffff">
		<h2>What are the units of volitional control?</h2>
	  <div style="text-align: left">
	    <p>Activity of control and non-control units</p>
	  	<ul>
	  		<li> BCIs induce widespread changes in activity and tuning in variety of tasks and task perturbations [e.g. Carmena et al 2003]
  			<li> Some studies show control unit specific changes in tuning [e.g. Law et al 2014]
	  	</ul> 

		<div class="fragment">
	  	<p>How do these effects manifest in a BCI paradigm where control units may be constrained by their role in ongoing movement?</p>
		</div>
		<div class="fragment">
			<hr>
		<div class="column4">
			<img src="assets/Adrienne-Fairhall.jpg" height="200px">
<p class="lcred">Adrienne Fairhall</div>
		<div class="column4">
			<img src="assets/Chet-Moritz.jpg" height="200px">
<p class="lcred">Chet Moritz</p></div>
		<div class="column4"><img src="assets/Cooper-Mellema.jpg" height="200px">
<p class="lcred">Cooper Mellema</p></div>
		<div class="column4-last"><img src="assets/Ivana-Milovanovic.jpg" height="200px"><br>
<p class="lcred">Ivana Milovanovic</p></div>
		</div>

	  <aside class="notes">
	    <span style="color: red"></span> •
	    • <span style="color: green"></span>
	  </aside>
	</section>

	<section data-background-color="#ffffff">
	<h2>Experiment</h2>
<img src="assets/Figure 1_monkey_ver3.png">
	<ul>
		<li> Utah multi-electrode array implanted in hand/wrist area of primary motor cortex of Macaque monkey
	</ul>
	  <aside class="notes">
	    <span style="color: red"></span> •
	    • <span style="color: green"></span>
	  </aside>
	</section>

	<section>
		<h2>Random target pursuit task</h2>
			<ul>
				<li> Target appears randomly outside radius from cursor position
				<li> Acquire target within fixed time, hold for 1s
			</ul>
	    <img src="assets/targettask.png" width="70%">
	  <aside class="notes">
	    <span style="color: red"></span> •

	    • <span style="color: green"></span>
	  </aside>
	</section>

	<section data-background-color="#ffffff">
	  <h2>Changes in effective connectivity of population</h2>
		<p>
	  	For a fixed network of units, compute transfer entropy between units in each condition:
	  	$$
	  	H_{X\to Y} = I(Y_t|Y_{t-1}, \dots, Y_{t-T}) - I(Y_t|Y_{t-1}, \dots, Y_{t-T},X_{t-1}, \dots, X_{t-T})
	  	$$
	  	for Shannon entropy $I$. <br><br>

	  	Study differences in connectivity between brain-, dual- conditions and (baseline) manual condition.<p>
	  <aside class="notes">
	    <span style="color: red"></span> •

	    • <span style="color: green"></span>
	  </aside>
	</section>

	<section data-background-color="#ffffff">
	  <h2>Changes in effective connectivity of population</h2>
	    <img src="assets/TE_part3.png" width="65%">
	    <p class="rcred"><b>Lansdell</b> et al <em>(submitted)</em></p>
	  <aside class="notes">
	    <span style="color: red"></span> •
	    • <span style="color: green"></span>
	  </aside>
	</section>

	<section data-background-color="#ffffff">
	  <h2>Changes in effective connectivity of population</h2>
	  	<ul>
	  		<li> Brain-control: overall decrease in effective connectivity to control units, regardless of co-tuning
	  		<li> Dual-control: functional connectivity between co-tuned units does not change, except when control unit involved
	  	</ul>
	  <aside class="notes">
	    <span style="color: red"></span> •


• <span style="color: green"></span>
	  </aside>
	</section>

	<section>
		<h2>Intrinsic variability predicts performance</h2>
		<p>Inspired by Sadtler et al 2014</p>
	    <img src="assets/intrinsic_manifold_white.png" width="75%">

	  <aside class="notes">
	    <span style="color: red"></span> •


• <span style="color: green"></span>
	  </aside>
	</section>

	<section data-background-color="#ffffff">
		<h2>Intrinsic variability predicts performance</h2>
<ul>
<li> Gaussian process factor analysis (GPFA) used to identify low-dimensional subspace
<li> Identify when spaces are significantly non-orthogonal
</ul>
	    <img src="assets/gpfa_perf.png" width="40%">
	  <aside class="notes">
	    <span style="color: red"></span> •
    • <span style="color: green"></span>
	  </aside>
	</section>

	<section data-background-color="#ffffff">
	  <h2>Intrinsic variability predicts performance</h2>
	    <img src="assets/Figure5_ver2c.png" width="60%">
	    <!--<img src="assets/Figure5_ver2d.png" width="60%">-->
	    <ul>
	    	<li> High performance requires at least one unit with high intrinsic variance
	    </ul> 
	  <aside class="notes">
	    <span style="color: red"></span> •

	    • <span style="color: green"></span>
	  </aside>
	</section>

	<section data-background-color="#ffffff">
	  <h2>Summary</h2>
	  	<ul>
	  		<li> Intrinsic variance of control units only variable found to predict performance and control unit contributions &#8212; motor unit tuning does not constrain how the task is performed
	  	</ul>
	  	<hr>
	  	<div class="fragment">
	  	<p>$\Rightarrow$ Provided basic neuronal constraints imposed by existing circuitry are taken into consideration, BCI design is able to leverage motor cortical adaptability.</p>
		<p> $\Rightarrow$ Internal and latent dynamics reveal additional information, compared with direct encoding models
		</div>
	  <aside class="notes">
	    <span style="color: red"></span> •

	    • <span style="color: green"></span>
	  </aside>
	</section>

<!-- ----------------------------------------------------------------------- -->
<!-- ----------------------------------------------------------------------- -->
<!-- ----------------------------------------------------------------------- -->

	<section data-background-color="#ffffff">
	  <h2>Outline</h2>
      <img src="assets/outline_2.svg" width="100%">

	  <aside class="notes">
	    <span style="color: red"></span> •
	    Ok, so we've seen how considerations of wrist tuning do not need to be
	    considered in a concurrent use BCI, that only factors of variance are predictive
	    of performance.

	    In the next section we will change gears a little bit and look at a model which
	    can help describe developmental processes that are relevant to the formation of
	    receptive fields in the retina. 
	    • <span style="color: green"></span>
	  </aside>
	</section>

	<section data-background-color="#000000">
	  <h2>Spontaneous activity in retina drives developmental programs</h2>
	  <div id="left">
	  	<ul>
	  		<li> Insight into structure of nervous system through study of developmental processes
	  		<li> Normal development of receptive fields in visual cortex relies on spontaneous activity in retina
	  		<li> Active or permissive role?
	  	</ul>
	  	<p><br></p>
	 	<div class="fragment">
	  	<div id="left" style="text-align: right;">
			<img src="assets/kevinford.jpg" height="200px" style="padding-right: 20px">
			<p class="rcred" style="padding-right: 20px">Kevin Ford </p>
	  	</div>
	  	<div id="right" style="text-align: left">
			<img src="assets/nathankutz.jpg" height="200px">
			<p class="lcred">Nathan Kutz</p>
	  	</div>
	  </div>
	  </div>
	  <div id="right">
		<img src="assets/cajal_retina.png" width="70%">
	 <p class="rcred">Ramón y Cajal</p>
	</div>
	  <aside class="notes">
	    <span style="color: red"></span> •
	    Want a model that can predict specific form of pharmacoligical manipulations
	    that may better help determine the precise role retinal waves play during development.


Vertebrate and invertebrate animals have similar neurons, and yet their nervous
systems function very differently. Freud and Cajal independently conjectured that it must be the
number of neurons, and how they inter-connect, that accounts for their different functionality.
A fundamental question is thus how does this connectivity arise? Two general developmental
processes can be described: first, genetically determined cues provide a coarse layout of cells and
connections and second, neural activity removes unwanted cells and refines connections. This
activity occurs not just through external stimulation, but also through correlated, spontaneously
generated bursts of action potentials occurring in hyperexcitable regions of the developing nervous
system prior to external input. Such activity has been implicated in the maturation of the retina,
spinal cord, hippocampus, cochlea, neocortex and a number of other regions [1]. To what extent
regions of the CNS rely on this activity for their development and what information they utilize for
this purpose is largely unknown.
	    • <span style="color: green"></span>
	  </aside>
	</section>

	<section data-background-color="#000000">
	  <h2>Retinal waves initiated and propagated by starburst amacrine cells (SACs)</h2>
	  <div>
		<img src="assets/retina_section.jpg" width="90%">
	 <p class="rcred">Josh Morgan 2005 (http://wonglab.biostr.washington.edu/research.html)</p>
	</div>
	  <aside class="notes">
	    <span style="color: red"></span> •

	    • <span style="color: green"></span>
	  </aside>
	</section>

	<section>
	  <h2>Retinal waves initiated and propagated by starburst amacrine cells (SACs)</h2>
	<video src="assets/Ford2011_suppmovie1.mp4" muted controls loop
	 poster="assets/dst2.png" class="slideautostart" width="70%"></video>
	 <p class="rcred">Ford et al 2012</p>
	  <aside class="notes">
	    <span style="color: red"></span> •

	    • <span style="color: green"></span>
	  </aside>
	</section>

	<section data-background-color="#ffffff">
	  <h2>Reaction-diffusion model of retinal waves</h2>
	  <p><br>
	  $$\begin{align*} C_{m}V_{t} & = -{\color{red}g_{Ca}(V-V_{Ca})}-{\color{green}g_{K}(R,S)(V-V_{K})}-{\color{red}g_{L}^{M}(V-V_{L})}-\\ 
	  & {\color{orange}g_{ACh}(V-V_{syn})}-{\color{blue}g_{n}^MN(V-V_{Ca})} \end{align*}$$
	  <br></p>
	  <ul>
	  	<li class="fragment"> <p style="color:#dd0000">Morris Lecar dynamics: refractory variable $R$</p>
	  	<li class="fragment"> <p style="color:#009900">Slow after-hyperpolarization (sAHP) current:</p> $$S_t = \gamma G(V) +S/\tau_S$$
	  	<li class="fragment"> <p style="color:#0000bb">Noise current initiates waves spontaneously: $N$ a Bernoulli RV</p> 
	  	<li class="fragment"> <p style="color:#ee9900">Diffusion/local coupling of ACh spreads waves:</p> $$\begin{align*} g_{ACh}(A) &= g_{ACh}^M\frac{\delta A^2}{1+\delta A^2} \\ 
	  		A_t &= D\nabla^2 A + \beta G(V) -\frac{A}{\tau_{ACh}}
	  		\end{align*}$$
	  </ul>
	  <aside class="notes">
	    <span style="color: red"></span> •

	    • <span style="color: green"></span>
	  </aside>
	</section>

	<section data-background-color="#ffffff">
	  <h2>Amacrine cell network as an excitable medium</h2>
	<video src="assets/ml_default_sol.mp4" muted controls loop
	 poster="assets/dst2.png" class="slideautostart" width="100%"></video>
	 <p class="rcred">Lansdell, Ford and Kutz PLoS Comp Bio. 2014</p>
	  <aside class="notes">
	    <span style="color: red"></span> •

	    • <span style="color: green"></span>
	  </aside>
	</section>

	<section data-background-color="#ffffff">
	  <h2>Model produces realistic cholinergic retinal waves</h2>
	    <img src="assets/retina_figure2.png" width="75%">
	  <aside class="notes">
	    <span style="color: red"></span> •

	    • <span style="color: green"></span>
	  </aside>
	</section>

	<section data-background-color="#ffffff">
	  <h2>When is the medium excitable?</h2>
	  <ul>
	  	<li> Non-dimensionalize, separate into fast-slow dynamics
	  		$$\begin{align*}
	  			v_t &= f(v,a;r)\\
	  			a_t &= \nabla^2 a + \frac{k(v,a)}{\tilde{\tau}_{ACh}}\\
	  		\end{align*} $$
	  	<li> Shift to traveling frame at speed $c$: $x' = x - ct; t' = t$
	  	<li> Heteroclinic orbit from rest to excited state is wave front
	  		$$\begin{align*}
	  			0 &= f(v,a;r) + cv'\\
	  			0 &= ca' + a'' + \frac{k(v,a)}{\tilde{\tau}_{ACh}}\\
	  		\end{align*} $$	  		
	  </ul>
	    <img src="assets/retina_figure3.png" width="100%">
	  <aside class="notes">
	    <span style="color: red"></span> •

	    • <span style="color: green"></span>
	  </aside>
	</section>

	<section data-background-color="#ffffff">
	  <h2>When is the medium excitable?</h2>
	  <ul>
	  	<li> Non-dimensionalize, separate into fast-slow dynamics
	  		$$\begin{align*}
	  			v_t &= f(v,a;r)\\
	  			a_t &= \nabla^2 a + \frac{k(v,a)}{\tilde{\tau}_{ACh}}\\
	  		\end{align*} $$
	  	<li> Shift to traveling frame at speed $c$: $x' = x - ct; t' = t$
	  	<li> Heteroclinic orbit from rest to excited state is wave front
	  		$$\begin{align*}
	  			0 &= f(v,a;r) + cv'\\
	  			0 &= ca' + a'' + \frac{k(v,a)}{\tilde{\tau}_{ACh}}\\
	  		\end{align*} $$	  		
	  </ul>
	    <img src="assets/retina_figure4.png" width="40%">
	  <aside class="notes">
	    <span style="color: red"></span> •

	    • <span style="color: green"></span>
	  </aside>
	</section>

	<section data-background-color="#ffffff">
	  <h2>Model predicts outcome of pharmacological manipulations</h2>
	  <ul>
	  	<li> Nicotinic ACh receptor agonists/antagonists affect conductance $g_{ACh}^M$
	  		<ul>
	  			<li> Wave speed highly sensitive to $g_{ACh}^M$.
	  			<li> Wave frequency affected
	  		</ul>
	  	<li> Forskolin affects second messenger cAMP, affects sAHP
	  		<ul>
	  			<li> Moderate change in wave frequency
	  			<li> No change in wave speed
	  		</ul>
	  </ul> 
	    <img src="assets/retina_figure5.png" width="80%">
	  <aside class="notes">
	    <span style="color: red"></span> •

	    • <span style="color: green"></span>
	  </aside>
	</section>

	<section data-background-color="#ffffff">
	  <h2>Analog to forest fire model exhibiting self-organized criticality </h2>
	  <ul>
	  	<li>Predicts when retinal waves exhibit power-law distributed wave sizes
	  </ul>
	    <img src="assets/retina_figure6.png" width="100%">
	  <div class="fragment">
	  <hr>
	  <ul>
	  	<li> Model determines spatiotemporal properties of waves
	  	<li> Can be used as a tool to investigate role of retinal waves in development
	  </ul>
	  </div>
	  <aside class="notes">
	    <span style="color: red"></span> •

	    • <span style="color: green"></span>
	  </aside>
	</section>

<!-- ---------------------------------------------------------------------- -->
<!-- ---------------------------------------------------------------------- -->
<!-- ---------------------------------------------------------------------- -->

	<section data-background-color="#ffffff">
	  <h2>Outline</h2>

    <img src="assets/outline_3.svg" width="100%">

	  <aside class="notes">
	    <span style="color: red"></span> •
	    Finally, I mentioned that ambiguities in representations in primary motor
	    cortex may become clear when we have access to a more comprehensive measure
	    of neural activity. These projects are becoming more common in lower animals,
	    so for the last section I would like to present work contributing to one of
	    these projects.
	    • <span style="color: green"></span>
	  </aside>
	</section>

	<section data-background-color="#000000">
	<h2>Comprehensive measures of neural activity in cnidaria &#8212 "cracking the neural code"</h2>
	  <div>
	<video src="assets/hydra_feeding_short.mp4" muted controls loop
	 poster="assets/dst2.png" class="slideautostart" width="60%"></video>
	 <p class="rcred">https://www.youtube.com/watch?v=dl_oVns2oa8</p>
	 <div class="fragment">
	<p>Why Hydra?</p>
	 <ol>
	 	<li> Small (0.5mm-1.5cm) &#8212; can fit into field of view of traditional microscope
	 	<li> Translucent; nerve net, easier imaging
	 	<li> Does not age, and can regenerate
	 </ol>
	</div>
	  </div>
	  <aside class="notes">
	    <span style="color: red"></span> •

	    • <span style="color: green"></span>
	  </aside>
	</section>

	<section>
	<h2>Hydra anatomy</h2>
	  <div>
	    <img src="assets/hydra_layers_white.png" width="100%" position="left">
	    <p class="rcred">Adapted from Technau and Steele 2011</p>
	  </div>
	  <aside class="notes">
	    <span style="color: red"></span> •

	    • <span style="color: green"></span>
	  </aside>
	</section>

	<section>
	<h2>Aims</h2>
<hr>Understand (and control) neuronal basis of simple behavior such as contracting/elongating and expelling
	    fluid (egestion)</p>
	     <div>
<hr><p>Sub-aims:</p>
	  	<ol>
	  	<li class="fragment highlight-green">Track Hydra pose</li>
	  	<li>Behavioral analysis</li>
	  	<li>Register and track neurons</li>
	  	<li>Record neural activity</li>
	  </ol>
	  </div>
	  <div class="fragment">
	  	<hr>
	  	<div class="column-left">
			<img src="assets/Adrienne-Fairhall.jpg" height="200px">
			<p class="lcred">Adrienne Fairhall</p>
	  	</div>
	  	<div class="column-center">
			<img src="assets/yuste.jpg" height="200px">
			<p class="lcred">Rafael Yuste</p>
		</div>
	  	<div class="column-right">
			<img src="assets/dupre.jpg" height="200px">
			<p class="lcred">Christophe Dupre</p>
	  	</div>
	  </div>
	  <aside class="notes">
	    <span style="color: red"></span> •

	    • <span style="color: green"></span>
	  </aside>
	</section>

	<section >
	<h2>Experiment</h2>
	  <div id="left">
	    <img src="assets/hydrasetup.jpg" width="50%">
	    <p class="rcred"></p>
	  </div>
	  <div id="right">
	    <img src="assets/hydrasetup3.jpg" width="100%" position="left">
	    <p class="rcred">C. Dupre, Yuste lab</p>
	  </div>
	    <p>Methods</p>
	    <ul>
	    <li> Create Act-GCaMP6s transgenic Hydra
		<li> Mount between coverslips separated by .1mm spacer
		<li> Image calcium transients
		</ul>
	  <aside class="notes">
	    <span style="color: red"></span> •

	    • <span style="color: green"></span>
	  </aside>
	</section>

	<section>
	<h2>Whole-body calcium imaging in Hydra</h2>
	<video src="assets/hydra_gcamp.mp4" muted controls loop
	 poster="assets/dst2.png" class="slideautostart" width="70%"></video>
	 <p class="rcred">C. Dupre, Yuste lab</p>
	  <aside class="notes">
	    <span style="color: red"></span> •

	    • <span style="color: green"></span>
	  </aside>
	</section>

	<section>
	<h2>Multi-frame optic flow image registration</h2>
	<img src="assets/mfsf_white.svg">
	  <aside class="notes">
	    <span style="color: red"></span> •

	    • <span style="color: green"></span>
	  </aside>
	</section>

	<section data-background-color="#ffffff">
	<h2>Tracking with optic flow: performance</h2>
		<div id="left">
		<p>Comparison to hand annotated neuron tracks<br>
		Per frame:</p>
		<ul>
		<li> at least 52% neurons are tracked within 6px
		<li> on average 82% neurons tracked within 6px
		</ul>
		Per neuron:
		<ul>
		<li> 42% neurons tracked within 6 px throughout all video
		</ul>
		</div>
		<div id="right">
<video src="assets/warp_neurons_nref100.mp4" muted controls loop
	 poster="assets/dst2.png" class="slideautostart"></video>
	</div>
	  <aside class="notes">
	    <span style="color: red"></span> •
	    
	    • <span style="color: green"></span>
	  </aside>
	</section>

	<section>
	<h2>Choosing which paths to associate</h2>
	Measure image registration error
		<img src="assets/combined.png">
		<div>
		<div class="column-left">Forward map $$g_{1,2}(\mathbf{x})$$</div>
		<div class="column-center">Reverse map $$g_{2,1}(\mathbf{x})$$</div>
		<div class="column-right">Error $$f_{1,2}(\mathbf{x}) = \left|g_{2,1}(g_{1,2}(\mathbf{x}))-\mathbf{x}\right|$$</div>
		</div>
		<br><img src="assets/colorwheel.png" align="left">
	  <aside class="notes">
	    <span style="color: red"></span> •
	    • <span style="color: green"></span>
	  </aside>
	</section>

	<section data-background-color="#ffffff">
	<h2>Exploiting periodicity in Hydra behavior</h2>
	<div id="left">
	<ul> 
	<br><br><br>
	Stereotyped Hydra behavior:<br>elongate then contract<br><br>
	Compute and measure optic flow error, $f_{ij}(x)$, between frames with regular spacing
	<br><br>'interframes' &#8212; every 250 frames
	</ul>
	</div>
	<div id="right" style="text-align: center;">
		Average error: $\langle f_{ij}(x)\rangle_\Omega$
		<img src="assets/similarity_orig.png">
		Frame index
	</div>

	  <aside class="notes">
	    <span style="color: red"></span> •
	    • <span style="color: green"></span>
	  </aside>
	</section>

	<section data-background-color="#ffffff">
	<h2>Exploiting periodicity in Hydra behavior</h2>
	<div id="left">
	Two clusters: contracted and elongated
	<p class="fragment"> 
	$\Rightarrow$ By registering regions of each interframe with a ref. frame we extend paths into temporally distant but positionally related frames<br>
	$\Rightarrow$ A mechanism to handle arbitrarily long videos without accumulation of tracking error
	</p>
	</div>
	<div id="right" style="text-align: center;">
		Average error: $\langle f_{ij}(x)\rangle_\Omega$<br>
		<img src="assets/dendrogram.png" width="70%">
	</div>
		<img src="assets/dend_d1_tile_c1.png" width="80%">
		<img src="assets/dend_d1_tile_c2.png" width="80%">
	  <aside class="notes">
	    <span style="color: red"></span> •
	    • <span style="color: green"></span>
	  </aside>
	</section>

	<section>
	<h2>Segmenting regions to register with each reference frame</h2>
		<p>For $K$ reference frames and $L$ interframes, let $f_{ij}(x)$ represent the optic flow error in using reference image $i$ to construct image $j$.<br>
		Use total variation image segmentation:
		$$\begin{align*}\min_{u_{kl}}\frac{1}{2}\sum_{k=1}^K\sum_{l=1}^L \int_\Omega |\nabla u_{kl}|\,dx
			+ \frac{\lambda}{2}\sum_{k=1}^K\sum_{l=1}^L \int_{\Omega} u_{kl}(x)f_{kl}(x)\,dx\end{align*}
		$$
		Solve with primal-dual algorithm (Chambolle and Pock 2011), accelerated on GPU.
		</p>
	<p class="fragment">
		Want number of ref frames to balance global registration vs registration error<br>
		$\Rightarrow$ Add a group LASSO penalty for number of reference frames used:
		$$\begin{align*}\min_{u_{kl}}\frac{1}{2}\sum_{k=1}^K\sum_{l=1}^L \int_\Omega |\nabla u_{kl}|\,dx
			+ \frac{\lambda}{2}\sum_{k=1}^K\sum_{l=1}^L \int_{\Omega} u_{kl}(x)f_{kl}(x)\,dx+ \frac{\lambda_2}{2}\sum_{k=1}^K\left(\sum_{l=1}^L \|u_{kl}\|^2_2 \right)^{1/2}\end{align*}
		$$
	</p>
	  <aside class="notes">
	    <span style="color: red"></span> •
	    • <span style="color: green"></span>
	  </aside>
	</section>

	<section>
	<h2>Method</h2>
		<p> 
			1. Select very sparse set of reference frames (ref frames)<br>
			2. Select regular set of inter-frames<br>
			<img src="assets/dend_d1_tile_c1_hl.png" width="90%"><br>
			<img src="assets/dend_d1_tile_c2_hl.png" width="90%"><br>
			3. Use optic flow+image segmentation to label regions mapping to reference frames<br>
			<img src="assets/mfsf_extend1.png" width="90%"><br>
		</p>
	  <aside class="notes">
	    <span style="color: red"></span> •
	    • <span style="color: green"></span>
	  </aside>
	</section>

	<section>
	<h2>Method</h2>
		<p> 
			4. Within each interframe block run MFSF for dense registration<br>
			<img src="assets/mfsf_extend2.png" width="90%"><br>
		</p>
	  <aside class="notes">
	    <span style="color: red"></span> •
	    • <span style="color: green"></span>
	  </aside>
	</section>

	<section>
	<h2>Method</h2>
		<p> 
			5. Associate each path from (4) with point in a ref frame using optic flow+segmentation (3)<br>
			<img src="assets/mfsf_extend3.png" width="90%"><br>
		</p>
		<p class="fragment">
			Thus every tracked path is associated with a point in a reference frame
		</p>
	  <aside class="notes">
	    <span style="color: red"></span> •
	    • <span style="color: green"></span>
	  </aside>
	</section>

	<section>
	<h2>Extending with $K=2; L = 8$</h2>
	<video src="assets/mfsf_dm_combined2.mp4" muted controls loop
	 poster="assets/dst2.png" class="slideautostart" width="55%"></video>
	  <aside class="notes">
	    <span style="color: red"></span> •
	    • <span style="color: green"></span>
	  </aside>
	</section>

	<section>
	<h2>Summary</h2>
	<ul>
		<li> Registration between similar frames &#8212 track Hydra pose throughout extended video sequences. 
		<li> Can be applied to other registration/tracking problems
	</ul>
	  <aside class="notes">
	    <span style="color: red"></span> •
	    • <span style="color: green"></span>
	  </aside>
	</section>

	<section>
	<p><br><br></p>
	"Progress in science depends on new techniques, new discoveries and new ideas, probably in that order" <br>
	&#8212; Sydney Brenner
	  <aside class="notes">
	    <span style="color: red"></span> •
	    So, it's open question what we will learn from these whole-brain imaging studies.
	    But, as we saw in the BCI project, properties to do with wrist encoding were only
	    so informative, while population analyses such as functional connectivity and intrinsic
	    manifolds were more informative. In a sense such tuning models are inspired by analyses of
	    single-unit recordings. Thus moving forward, it's useful to keep in mind.
	    • <span style="color: green"></span>
	  </aside>
	</section>

<!-- ----------------------------------------------------------------------- -->
<!-- ----------------------------------------------------------------------- -->
<!-- ----------------------------------------------------------------------- -->

	<section>
	  <h2>Acknowledgments</h2>
	  	<hr>
	  <div id="left">
	  	<ul>
         <li> Adrienne Fairhall</li>
         <li> Chet Moritz</li>
         <li> Eric Shea-Brown</li>
         <li> Emily Fox</li>
     </ul>
     <ul>
         <li> Ivana Milovanovic</li>
         <li> Cooper Mellema</li>
         <li> Eberhard Fetz</li>
	  	</ul>
   	  </div>
	  <div id="left">
	  	<ul>
         <li> Fairhall lab (UW)</li><ul>
         	<li> Anatoly Buchin </li></ul>
         <li> Moritz lab (UW)</li><ul>
         	<li> Charlie Matlack </li>
         	<li> Robert Robinson</li></ul>
         <li> Yuste lab (Columbia)</li><ul>
         <li> Rafael Yuste</li>
         <li> Thibault Lagache</li>
         <li> Christophe Dupre</li>
         <li> John Szymanski</li></ul>
	  	</ul>
   	  </div>
	  <aside class="notes">
	    <span style="color: red"></span> •
	    • <span style="color: green"></span>
	  </aside>
	</section>

<!-- ----------------------------------------------------------------------- -->
<!-- ----------------------------------------------------------------------- -->
<!-- ----------------------------------------------------------------------- -->

	<section>
	<h2>Segmenting regions to extend</h2>
	<div id="left">
		Mumford-Shah image segmention: divide into $k$ regions of constant color, while trying to minimize perimeter of region boundaries
	</div>
	<div id="right"><img src="assets/butterfly_together.png"></div>
		$$\begin{align*}\min_{(R_l),c_l}\frac{1}{2}\sum_{l=1}^k \text{Per}(R_l;\Omega)
			+ \frac{\lambda}{2}\sum_{l=1}^k \int_{R_l} |g(x)-c_l|^2\,dx\end{align*}$$
	  <aside class="notes">
	    <span style="color: red"></span> •
	    • <span style="color: green"></span>
	  </aside>
	</section>

	<section>
	<h2>Segmenting regions to extend</h2>
	<div id="left">
		Mumford-Shah image segmention: divide into $k$ regions of constant color, while trying to minimize perimeter of region boundaries
	</div>
	<div id="right"><img src="assets/butterfly_together.png"></div>
	<p>
		$$\begin{align*}\min_{u_l}\frac{1}{2}\sum_{l=1}^k \int_\Omega |\nabla u_l|\,dx
			+ \frac{\lambda}{2}\sum_{l=1}^k \int_{\Omega} u_l(x)f_l(x)\,dx\end{align*}
		$$
		with $f_l(x) = |g(x)-c_l|^2$. Assume $c_l$ are known and $\mathbf{u}\in U$:
		$$
		U = \left\{u_l:\sum_l^k u_l(x) = 1, \quad u_l(x) \ge 0, \forall x\in\Omega\right\}
		$$
		Convex in $\mathbf{u}$<br>
		Select color via $v(x) = \text{argmax}_l u_l(x)$ 
	</p>
	  <aside class="notes">
	    <span style="color: red"></span> •
	    • <span style="color: green"></span>
	  </aside>
	</section>

	<section>
	<h2>Mumford-Shah image segmentation</h2>
	<p>
		Chambolle algorithm solves problems:
		$$\min_{x\in X}F(Kx) + G(x)$$
		for convex $F(\cdot):Y\to [0,\infty]$ and $G(\cdot):X\to [0,\infty]$, 
		<br>in primal-dual form:
		$$\min_{x\in X}\max_{y\in Y} \langle Kx, y\rangle - F^*(y) + G(x)$$
		<em>Algorithm:</em>
	</p>
	<ol>
	<li> Initialization: $\tau, \sigma > 0, \theta \in [0,1], (x^0,y^0)\in X\times Y$. Set $\bar{x}^0 = x^0$
	<li> Iterate until convergence: ($n\ge 0$)
		$$\begin{align}
		y^{n+1} &= \pi_{F^*}(y^n + \sigma K \bar{x}^n; \sigma)\\
		x^{n+1} &= \pi_G(x^n - \tau K^* {y}^{n+1}; \tau)\\
		\bar{x}^{n+1} &= x^{n+1} +\theta(x^{n+1} - x^n)
		\end{align}$$
	</ol>
	  <aside class="notes">
	    <span style="color: red"></span> •
	    • <span style="color: green"></span>
	  </aside>
	</section>

	<section>
	<h2>Mumford-Shah image segmentation</h2>
	<p>
		With proximal operator
		$$
		\pi_G(y;\tau) = \text{argmin}_{x}\frac{\|x-y\|_2^2}{2\tau}+G(x)
		$$
		<br>
		Primal-dual MS image segmentation:  
		$$\begin{align}\min_{u=(u_l)_{l=1}^k} \max_{p=(p_l)_{l=1}^k} &\left(\sum_{l=1}^k\langle \nabla u_l, p_l \rangle +\langle u_l, f_l \rangle \right) +\delta_U(u) - \delta_P(p) \end{align}$$
		So,
		<ul>
		<li> $K = \nabla$ (first order forward difference)
		<li> $K^* = -\text{div}$ (first order backward difference)
		<li> $F^*(p) = \delta_P(p)$ with $P=\left\{ p\in Y^k:\|p_l\|_\infty \le \frac{1}{2}\right\}$
		<li> $G(u) = \delta_U(u)$
		</ul>
		Proximal operaters $\pi_{F^*}$ and $\pi_G$ are pixel-wise projection onto convex sets $P$ and $U$
		$\Rightarrow$ Easy to implement on GPU
	</p>
	  <aside class="notes">
	    <span style="color: red"></span> •
	    • <span style="color: green"></span>
	  </aside>
	</section>

	<section>
	<h2>Segmentation of tracked regions</h2>

		<p>For $K$ reference frames and $L$ iframes, let $f_{ij}(x)$ represent the optic flow error in using reference image $i$ to construct image $j$.  
		$$\begin{align}\min_{u} \max_{p} \sum_{l=1}^L\left(\sum_{k=1}^K\langle \nabla u_{kl}, p_{kl} \rangle +\langle u_{kl}, f_{kl} \rangle \right) +\delta_U(u) - \delta_P(p) \end{align}$$
		</p>
	  <aside class="notes">
	    <span style="color: red"></span> •
	    • <span style="color: green"></span>
	  </aside>
	</section>

	<section>
	<h2>Choosing ref frames</h2>
	<p>
		Want number of ref frames to balance global registration vs registration error <br><br>
		Add a group LASSO penalty for number of reference frames used:
		$$\begin{align}\min_{u=(u_l)_{l=1}^k} \max_{p=(p_l)_{l=1}^k} &\left(\sum_{l=1}^k\langle \nabla u_l, p_l \rangle +\langle u_l, f_l \rangle \right) +\delta_U(u) - \delta_P(p) +\frac{\lambda_2}{2}\sum_{k=1}^K\left(\sum_{l=1}^L \|u_{kl}\|^2_2 \right)^{1/2} \end{align}$$
		The proximal operator $\pi_G$ now becomes:
		$$
		\pi_G(y;\tau) = \text{argmin}_{x}\frac{\|x-y\|_2^2}{2\tau}+\frac{\lambda_2}{2}\sum_{k=1}^K\left(\sum_{l=1}^L \|y_{kl}\|^2_2 \right)^{1/2}+\delta_U(y)
		$$
		Compute $\pi_G$ with ADMM
	</p>
	  <aside class="notes">
	    <span style="color: red"></span> •
	    • <span style="color: green"></span>
	  </aside>
	</section>

	<section>
	<h2>Multi-frame optic flow image registration</h2>
	<ul id="blanklist">
	<li> Dense optic flow with subspace constraints (MFSF, Garg et al 2013)
	<li> For each pixel find linear combination of basis paths, $L$, that minimize energy<br>
	<img src="assets/energyeq.png">
	<li> $I_f$ = image at frame $f$,
	<li> $I_0$ = reference frame (need not be first frame of video),
	<li> $Q_f^u$, $Q_f^v$ = basis paths at frame $f$, 
	<li> $\alpha$ = smoothness regularizer
	</ul>
	  <aside class="notes">
	    <span style="color: red"></span> •

	    • <span style="color: green"></span>
	  </aside>
	</section>


    <!--<script src="reveal.js/js/reveal.min.js"></script>-->
    <script src="reveal.js/js/reveal.js"></script>
    <script src="pdfjs/compatibility.js"></script>
    <script src="pdfjs/pdf.js"></script>

    <script src="lib/js/head.min.js"></script>
    <script>
      head.js(
        "lib/js/jquery.min.js",
        "lib/js/jquery.hotkeys.js",
        "lib/js/underscore.min.js",
        "lib/js/swfobject.js",
        "lib/js/dat.gui.js",
        "lib/js/EventEmitter.js",

        //"lib/js/three.js",
        "lib/js/three/EffectComposer.js",
        "lib/js/three/RenderPass.js",
        "lib/js/three/BloomPass.js",
        "lib/js/three/ShaderPass.js",
        "lib/js/three/MaskPass.js",

        // three shaders
        "lib/js/three/shaders/CopyShader.js",
        "lib/js/three/shaders/BasicShader.js",
        "lib/js/three/shaders/DotScreenShader.js",
        "lib/js/three/shaders/UnpackDepthRGBAShader.js",
        "lib/js/three/shaders/HorizontalBlurShader.js",
        "lib/js/three/shaders/VerticalBlurShader.js",

        // js files needed for WebGL specific samples (excluding three js)
        "lib/js/J3DI.js",
        "lib/js/J3DIMath.js",
        "lib/js/webgl-utils.js",
        "lib/js/webgl-debug.js",

        // App specific js
        //"js/reveal.min.js",
        "js/stats_bootstrap.js",
        "js/samples.js",
        //"js/dat.gui.bootstrap.js",

		function() {
      Reveal.initialize({
        controls: false,
        progress: true,
        history: true,
        center: false,
        keyboard: true,
        touch: false,
        overview: true,
        mouseWheel: false,
        width: 960,
        height: 720,

        theme: false, // hardcoded with CSS import in <head>
        transition: 'fade', // default/cube/page/concave/zoom/linear/fade/none
        transitionSpeed: 'default', // default/fast/slow

        math: {
          mathjax: 'mathjax/MathJax.js',
          config: 'TeX-AMS_HTML-full',
        },

        dependencies: [
          { src: 'reveal.js/lib/js/classList.js',
	    condition: function() { return !document.body.classList; }},
          { src: 'reveal.js/plugin/markdown/marked.js',
	    condition: function() { return !!document.querySelector ('[data-markdown]'); }},
          { src: 'reveal.js/plugin/markdown/markdown.js',
	    condition: function() { return !!document.querySelector ('[data-markdown]'); }},
          { src: 'reveal.js/plugin/highlight/highlight.js', async: true,
	    callback: function() { hljs.initHighlightingOnLoad (); }},
          { src: 'reveal.js/plugin/notes/notes.js', async: true,
	    condition: function() { return !!document.body.classList; }},
          { src: 'mymath.js', async: true },
	  { src: 'pdfimgs.js', async: true },
	  { src: 'slideautostart.js', async: true },
        ],
      });
    });
    </script>
  </body>
</html>
